{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae410d1d-dcce-419a-a3df-e48c14915d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54d159d06d34a4e9700a39b69f91d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01,\\x00\\x00\\x007\\x08\\x06\\x00\\x00\\x00\\xb6\\x1bw\\x99\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MESA-INTEL: warning: cannot initialize blitter engine\n",
      "Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n",
      "Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n",
      "Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n",
      "Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n",
      "Detected skylake derivative running on mesa i915. Clears to srgb textures will use manual shader clears.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "🯄 (default) | Intel(R) Arc(tm) Graphics (MTL) | IntegratedGPU | Vulkan | Mesa 24.0.8-1\n",
      "❗ | llvmpipe (LLVM 17.0.6, 256 bits) | CPU | Vulkan | Mesa 24.0.8-1 (LLVM 17.0.6)\n",
      "❗ | Mesa Intel(R) Arc(tm) Graphics (MTL) | IntegratedGPU | OpenGL | \n"
     ]
    }
   ],
   "source": [
    "# lfp: spike and rastor\n",
    "import pynaviz as viz\n",
    "import pynapple as nap\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5678219-7a1e-4699-8ed4-335a7e7a9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caitlin/venvs/pynaviz/lib/python3.11/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.5.0 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/home/caitlin/venvs/pynaviz/lib/python3.11/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.4.0 because version 2.7.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/home/caitlin/venvs/pynaviz/lib/python3.11/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-experimental' version 0.1.0 because version 0.5.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mouse32-140822\n",
       "┍━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━┑\n",
       "│ Keys                  │ Type        │\n",
       "┝━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━┥\n",
       "│ units                 │ TsGroup     │\n",
       "│ sws                   │ IntervalSet │\n",
       "│ rem                   │ IntervalSet │\n",
       "│ position_time_support │ IntervalSet │\n",
       "│ epochs                │ IntervalSet │\n",
       "│ ry                    │ Tsd         │\n",
       "┕━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━┙"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pynapple as nap\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import pandas as pd\n",
    "\n",
    "def smooth_series(series, sigma=1):\n",
    "    smoothed_series = gaussian_filter1d(series, sigma=sigma, mode='constant')\n",
    "    return pd.Series(smoothed_series, index = series.index)\n",
    "\n",
    "def smoothAngularTuningCurves(tuning_curves, window = 20, deviation = 3.0):\n",
    "    new_tuning_curves = {}  \n",
    "    for i in tuning_curves.columns:\n",
    "        tcurves = tuning_curves[i]\n",
    "        offset = np.mean(np.diff(tcurves.index.values))\n",
    "        padded  = pd.Series(index = np.hstack((tcurves.index.values-(2*np.pi)-offset,\n",
    "                                                tcurves.index.values,\n",
    "                                                tcurves.index.values+(2*np.pi)+offset)),\n",
    "                            data = np.hstack((tcurves.values, tcurves.values, tcurves.values)))\n",
    "        # smoothed = padded.rolling(window=window,win_type='gaussian',center=True,min_periods=1).mean(std=deviation)\n",
    "        smoothed = smooth_series(padded, sigma=deviation)\n",
    "        new_tuning_curves[i] = smoothed.loc[tcurves.index]\n",
    "\n",
    "    new_tuning_curves = pd.DataFrame.from_dict(new_tuning_curves)\n",
    "\n",
    "    return new_tuning_curves\n",
    "\n",
    "def get_memory_map(filepath, nChannels, frequency=20000):\n",
    "    \"\"\"Summary\n",
    "    \n",
    "    Args:\n",
    "        filepath (TYPE): Description\n",
    "        nChannels (TYPE): Description\n",
    "        frequency (int, optional): Description\n",
    "    \"\"\"\n",
    "    n_channels = int(nChannels)    \n",
    "    f = open(filepath, 'rb') \n",
    "    startoffile = f.seek(0, 0)\n",
    "    endoffile = f.seek(0, 2)\n",
    "    bytes_size = 2      \n",
    "    n_samples = int((endoffile-startoffile)/n_channels/bytes_size)\n",
    "    duration = n_samples/frequency\n",
    "    interval = 1/frequency\n",
    "    f.close()\n",
    "    fp = np.memmap(filepath, np.int16, 'r', shape = (n_samples, n_channels))        \n",
    "    timestep = np.arange(0, n_samples)/frequency\n",
    "\n",
    "    return fp, timestep\n",
    "\n",
    "\n",
    "\n",
    "# LOADING DATA FROM NWB\n",
    "data = nap.load_file(\"/media/caitlin/02B2-43B3/data/Mouse32-140822.nwb\")\n",
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f40c1b7-efff-42d7-b391-1bdeb19b6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = data[\"units\"]\n",
    "head_direction = data[\"ry\"]\n",
    "wake_ep = data[\"position_time_support\"]\n",
    "\n",
    "# COMPUTING TUNING CURVES\n",
    "tuning_curves = nap.compute_1d_tuning_curves(\n",
    "    spikes, head_direction, 120, minmax=(0, 2 * np.pi)\n",
    ")\n",
    "\n",
    "# Loading LFP\n",
    "fp, t = get_memory_map(\"/media/caitlin/02B2-43B3/data/Mouse32-140822.eeg\", 69, 1250)\n",
    "lfp = nap.TsdFrame(t=t, d=fp)\n",
    "\n",
    "# The right epoch\n",
    "\n",
    "ep = nap.IntervalSet(\n",
    "    start=10717, end=10735\n",
    ")  # Select an arbitrary interval for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263a2aaf-a2a5-4a00-a424-d27446e07661",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.array([26, 30, 25, 31, 24, 28, 27, 29, 22, 17, 23, 16, 20, 19, 21, 18, 48, 57, 49, 56, 50, 54, 52, 53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1697672-db1e-44a1-bd10-778a9f8959e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 30, 25, 31, 24, 28, 27, 29, 22, 17, 23, 16, 20, 19, 21, 18, 48,\n",
       "       57, 49, 56, 50, 54, 52, 53])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9598c4a-3291-4fbd-95ef-c318b8e9a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp = lfp.restrict(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcd9b034-72cf-479a-949d-2a8ff37176e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp = lfp[:, ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf5ca77-d3b1-4636-b7f5-3ba8d4dda49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes2 = nap.TsGroup(data= {i: v for i, v in enumerate(spikes.data.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360dd023-682a-4473-bff3-0ebdac46a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes2.set_info(location=spikes.location.values, group=spikes.group.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf62466-3125-478c-aa11-a7d54367ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing\n",
    "\n",
    "# COMPUTING TUNING CURVES\n",
    "tuning_curves = nap.compute_1d_tuning_curves(\n",
    "    spikes2, head_direction, 120, minmax=(0, 2 * np.pi)\n",
    ")\n",
    "tuning_curves = smoothAngularTuningCurves(tuning_curves)\n",
    "\n",
    "si = nap.compute_1d_mutual_info(tuning_curves, head_direction, wake_ep)\n",
    "\n",
    "order = np.argsort(np.argmax(tuning_curves.values, 0))\n",
    "\n",
    "spikes2.set_info(peak=tuning_curves.idxmax(), si=si['SI'])\n",
    "\n",
    "spikes2 = spikes2.getby_category(\"location\")['adn'].getby_threshold(\"si\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1634add-9f6b-46e7-b5e2-6e739b7e1959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index    rate      location    group    peak     si\n",
       "-------  --------  ----------  -------  -------  -------\n",
       "4        0.30207   adn         2        1.59698  1.22464\n",
       "5        0.87042   adn         2        1.91114  0.16498\n",
       "6        0.36154   adn         2        1.7017   1.18569\n",
       "7        10.51737  adn         2        1.64934  1.06815\n",
       "8        2.62475   adn         2        5.31453  0.49214\n",
       "9        2.55818   adn         2        2.38237  0.86329\n",
       "10       7.06715   adn         2        4.05789  0.50904\n",
       "...      ...       ...         ...      ...      ...\n",
       "28       1.78011   adn         4        5.99521  0.15728\n",
       "29       4.23006   adn         4        3.01069  1.83191\n",
       "30       2.15215   adn         4        4.21497  0.72279\n",
       "31       0.58829   adn         4        0.70686  1.6722\n",
       "32       1.12899   adn         4        1.91114  0.93687\n",
       "33       5.26316   adn         4        3.69137  0.95485\n",
       "34       1.57122   adn         4        0.86394  1.16114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cfbcb28-4038-428a-a55e-0b3afce9dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caitlin/repos/fastplotlib/fastplotlib/graphics/_features/_base.py:21: UserWarning: casting float64 array to float32\n",
      "  warn(f\"casting {array.dtype} array to float32\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Key 0 not in group index.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[43mviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNeuroWidget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_direction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mraster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspikes2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLFP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHead Direction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpikes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvertical_plots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/pynaviz/pynaviz/neurowidget.py:95\u001b[0m, in \u001b[0;36mNeuroWidget.__init__\u001b[0;34m(self, line, heatmap, movie, rois, raster, names, vertical_plots, time_interval)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visuals\u001b[38;5;241m.\u001b[39mappend(visual)\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;66;03m# generate visual based on viz type, pynapple object pairing\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m             visual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_visual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisual_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mviz_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mviz_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visuals\u001b[38;5;241m.\u001b[39mappend(visual)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# if vertical, stack subplots on top of one another\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/pynaviz/pynaviz/neurowidget.py:197\u001b[0m, in \u001b[0;36mNeuroWidget._make_visual\u001b[0;34m(visual_type, data, time_interval)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m visual\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraster\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 197\u001b[0m     visual \u001b[38;5;241m=\u001b[39m \u001b[43mRasterItem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m visual\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/pynaviz/pynaviz/store_items/raster.py:41\u001b[0m, in \u001b[0;36mRasterItem.__init__\u001b[0;34m(self, data, time_interval)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# format raster data and make scatter graphics\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 41\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mget(min_time, max_time)\u001b[38;5;241m.\u001b[39mt\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# dummy data if there is no spiking in the time interval in order to keep index ordering\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/repos/pynapple/pynapple/core/ts_group.py:244\u001b[0m, in \u001b[0;36mTsGroup.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_info(key)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m not in group index.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key))\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# array boolean are transformed into indices\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# note that raw boolean are hashable, and won't be\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# tsd == tsg.to_tsd()\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(key)\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Key 0 not in group index.'"
     ]
    }
   ],
   "source": [
    "nw = viz.NeuroWidget(line=[lfp, head_direction],\n",
    "                     raster=spikes2, \n",
    "                     names=[\"LFP\", \"Head Direction\", \"Spikes\"],\n",
    "                     vertical_plots=True,\n",
    "                     time_interval=ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da6d50-6bef-440a-85d0-d22235b8dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1cdc4d-a9c8-4ece-bf60-48fa15a05e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    " 0: [26, 30, 25, 31, 24, 28, 27, 29],\n",
    " 1: [22, 17, 23, 16, 20, 19, 21, 18],\n",
    " 2: [48, 57, 49, 56, 50, 54, 52, 53],\n",
    " # 3: [58, 51, 60, 55, 61, 59, 62, 63],\n",
    " # 4: [45, 36, 41, 34, 37, 35, 33, 32],\n",
    " # 5: [39, 46, 38, 47, 40, 44, 43, 42],\n",
    " # 6: [15, 8, 14, 9, 13, 10, 12, 11],\n",
    " # 7: [7, 0, 6, 1, 5, 2, 4, 3],\n",
    " # 8: [64, 65, 66, 67, 68]\n",
    "}\n",
    "\n",
    "groups = {\n",
    " 0: [0, 1, 2, 3, 4, 5, 6, 7],\n",
    " 1: [8, 9, 10, 11, 12, 13, 14, 15],\n",
    " 2: [16, 17, 18, 19, 20, 21, 22, 23],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95a31f4a-7e29-48fd-aec0-e9a37d9a6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw.figure[0,0].graphics[0][groups[0]].colors = \"lime\"\n",
    "nw.figure[0,0].graphics[0][groups[1]].colors = \"hotpink\"\n",
    "nw.figure[0,0].graphics[0][groups[2]].colors = \"cyan\"\n",
    "# nw.figure[0,0].graphics[0][groups[3]].colors = \"orange\"\n",
    "# nw.figure[0,0].graphics[0][groups[4]].colors = \"green\"\n",
    "# nw.figure[0,0].graphics[0][groups[5]].colors = \"aqua\"\n",
    "# nw.figure[0,0].graphics[0][groups[6]].colors = \"magenta\"\n",
    "# nw.figure[0,0].graphics[0][groups[7]].colors = \"yellow\"\n",
    "# nw.figure[0,0].graphics[0][groups[8]].colors = \"lime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212c971-58d8-4399-93cc-4658330c721a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f215b24d-daf8-4987-8aab-ad9a323881df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def generate_colors(peaks):\n",
    "    # Normalize peak values to be between 0 and 1\n",
    "    normalized_peaks = (peaks - np.min(peaks)) / (np.max(peaks) - np.min(peaks))\n",
    "    \n",
    "    # Sample colors from the HSV colormap based on normalized peaks\n",
    "    hsv_colors = plt.cm.hsv(normalized_peaks)\n",
    "    \n",
    "    # Ensure the output has the shape (#peaks, 4)\n",
    "    return hsv_colors\n",
    "\n",
    "# Example usage\n",
    "num_lines = len(nw.visuals[2].graphic)  # Replace with the number of lines you have\n",
    "colors = generate_colors(spikes2.peak.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7370085e-f71b-4493-a1f6-d591ed68b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, g in zip(colors, nw.visuals[2].graphic):\n",
    "    g.colors = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1967a-4b7f-439f-89b3-a11b599adffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a35d7324-10bd-469d-ad89-d4139adeaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nw.figure.export(\"/home/caitlin/Desktop/bah.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7c0fd-50e2-4833-852e-3edf0637d431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
